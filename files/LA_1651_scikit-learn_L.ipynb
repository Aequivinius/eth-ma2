{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a467093",
   "metadata": {},
   "source": [
    "# LA_1651\n",
    "\n",
    "Nachdem Sie in der `LA_1650` gesehen haben, wie eine ML-*pipeline* im einfachsten Fall aussehen kann, gehen wir nun in diesem gr√∂√üeren Auftrag einen Schritt weiter, und versuchen, einen weniger vorgetretenen Pfad zu begehen: Statt des vorbereiteten Iris-Datensatzes versuchen wir nun, ein Modell f√ºr unseren Titanic-Datensatz zu erstellen, und k√∂nnen somit auf einige Feinheiten eingehen!\n",
    "\n",
    "‚ö†Ô∏è In diesem Auftrag m√ºssen Sie viel [recherchieren](https://scikit-learn.org/stable/user_guide.html) und in den vorhergegangenen Auftr√§gen nachlesen, welche Funktionen wie heissen und welche Parameter diese haben - lassen Sie sich nicht frustrieren, *that's part of the job!* und mit etwas √úbung wird es Ihnen in Zukunft leichter fallen, schnell an die wichtigen Informationen zu kommen. Ansonsten l√§uft dieser Auftrag aber wie in den bisherigen Notizb√ºchern ab - f√ºllen Sie die Teile ein, die mit `# üëæ TODO` markiert sind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef47f3e",
   "metadata": {},
   "source": [
    "## Teil 1: Laden der Daten\n",
    "\n",
    "Im `LA_1650` konnten wir den Iris-Datensatz direkt durch `sklearn` importieren; dieser [Spielzeug-Datensatz](https://scikit-learn.org/stable/datasets/toy_dataset.html) wird mitgeliefert. Aber nat√ºrlich k√∂nnen Sie nicht Ihre ML-Karriere nur auf mitgelieferten Datens√§tzen aufbauen, darum geht es in diesem ersten Schritt darum, wie Sie andere Datens√§tze f√ºr `sklearn` zug√§nglich machen. Gl√ºcklicherweise ist `sklearn` weitgehend mit `pandas` kompatibel, und so k√∂nnen Sie den Titanic-Datensatz laden, wie Sie es sich gewohnt sind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1732e224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "      sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0  female   NaN      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1    male  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2  female  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3  female  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4    male  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  \n",
       "0                       NaN         1  \n",
       "1                   Croatia         0  \n",
       "2                       NaN         0  \n",
       "3      Cornwall / Akron, OH         1  \n",
       "4  Barre, Co Washington, VT         0  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Load the titanic_train data set into a pandas DataFrame\n",
    "import pandas as pd\n",
    "import os\n",
    "path = os.path.join(\"titanic-dataset\",\"titanic_train.csv\")\n",
    "titanics = pd.read_csv(path)\n",
    "titanics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80017c6",
   "metadata": {},
   "source": [
    "## Teil 2: Bestimmen von *features* und *targets*\n",
    "\n",
    "Es ist die Frage ein wenig Ihnen √ºberlassen: Ausgelegt ist der Datensatz nat√ºrlich, vorherzusagen, ob jemand √ºberlebt hat oder nicht, ob von welchen Faktoren diese am st√§rksten abh√§ngt. Aber Sie k√∂nnten nat√ºrlich auch andere Dinge versuchen vorherzusagen (Ticketpreis abh√§ngig von Alter?). In jedem Fall m√ºssen Sie aber die Daten nun aufteilen, sodass Sie ein `DataFrame` namens `X` haben, in welchem sich die *features* befinden; und ein `y` mit den *targets*, die Sie vorhersagen m√∂chten. Suchen Sie also interessante *features* (in diesem Fall: `pclass`, `age`, `sex`, `fare`, `embarked`, `party_size`), auf denen Ihre Analyse aufbaut, und teilen Sie die urspr√ºngliche `DataFrame` anhand der ausgesuchten Spalten auf.\n",
    "\n",
    "Hier ist auch ein guter Punkt, an dem Sie *feature engineering* betreiben, also das Erstellen neuer Spalten, welche Informationen auf eine besonders n√ºtzliche Art darstellen. Sie k√∂nnen hier gut das Beispiel mit der `PartySize` aus der `LA_1618` √ºbernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "72e97692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>party_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>male</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>female</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass   age     sex     fare embarked  party_size\n",
       "0       3   NaN  female   7.7333        Q           1\n",
       "1       3  38.0    male   8.6625        S           1\n",
       "2       3  30.0  female  24.1500        S           3\n",
       "3       2  54.0  female  23.0000        S           5\n",
       "4       2  40.0    male  13.0000        S           1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Split the titanic data into suitable X and y variables\n",
    "titanics[\"party_size\"] = titanics[\"sibsp\"] + titanics[\"parch\"] + 1\n",
    "X = titanics[[\"pclass\", \"age\", \"sex\", \"fare\", \"embarked\", \"party_size\"]]\n",
    "y = titanics[[\"survived\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f208b0a",
   "metadata": {},
   "source": [
    "## Teil 3: *preprocessing*\n",
    "\n",
    "Gehen wir davon aus, dass Sie `age`, `sex` und `fare` gew√§hlt haben. Dies Werte dieser Spalten k√∂nnen Sie nicht einfach *tel quel* verwenden, sondern diese Bed√ºrfen des *preprocessing*. Zun√§chst m√ºssen Sie sich √ºberlegen, wie Sie mit fehlenden Werten umgehen - was soll der Algorithmus tun, wenn er eine Zahl erwartet, und stattdessen ein `NaN` liest? Sie k√∂nnten einfach alle Zeilen mittels `.dropna()` l√∂schen, welche irgendwo `NaN` beinhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6ff9cda3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code shows you how many rows contain NaN values\n",
    "len(X[X.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44e333",
   "metadata": {},
   "source": [
    "Das sind fast 20% unserer Daten, die wir l√∂schen w√ºrden - das ist zuviel! Besser also, wir √ºberlegen uns eine schlauere L√∂sung: Lesen Sie in der [Dokumentation unter 6.4.2](https://scikit-learn.org/stable/modules/impute.html#univariate-feature-imputation) nach, wie Sie `NaN`-Werte durch den Modus ersetzen, und f√ºllen Sie so fehlende Werte auf! Beachten Sie dabei:\n",
    "\n",
    "* Sie m√ºssen `numpy` importieren, damit Sie `np.nan` verwenden k√∂nnen\n",
    "* Die `transform`-Funkion gibt Ihnen statt eine `DataFrame` ein einfaches Array zur√ºck, welches Sie wieder zur√ºck-konvertieren m√ºssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "04cc62a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Fill NaNs with modes\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "si.fit(X)\n",
    "X_ = si.transform(X)\n",
    "X = pd.DataFrame(X_, columns=X.columns)\n",
    "len(X[X.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d026e",
   "metadata": {},
   "source": [
    "Gehen wir einen Schritt weiter - ML-Algorithmen sch√§tzen als `string` dargestellte kategorische Daten nicht (sehen Sie ggf. in der `PR_1604_Datentypen` nach), weshalb wir diese ersetzen m√ºssen. Statt `male` soll also jeweils `0`, und statt `female` jeweils `1` stehen - aber wir wollen das nat√ºrlich nicht von Hand umsetzen, sondern verwenden einen `OrdinalEncoder`, welcher das f√ºr uns √ºbernimmt: Lesen Sie hierf√ºr zun√§chst das [Kapitel 6.3.4](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features). Den dort auch erw√§hnten `OneHotEncoder` k√∂nnen Sie gleich verwenden, um die `embarked`-Spalte zu enkodieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b2d34b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>party_size</th>\n",
       "      <th>London</th>\n",
       "      <th>Queenstown</th>\n",
       "      <th>Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass   age  sex    fare party_size  London  Queenstown  Southampton\n",
       "0      3  18.0  0.0  7.7333          1     0.0         1.0          0.0\n",
       "1      3  38.0  1.0  8.6625          1     0.0         0.0          1.0\n",
       "2      3  30.0  0.0   24.15          3     0.0         0.0          1.0\n",
       "3      2  54.0  0.0    23.0          5     0.0         0.0          1.0\n",
       "4      2  40.0  1.0    13.0          1     0.0         0.0          1.0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Use OrdinalEncoder for the sex-column, \n",
    "# and the OneHotEncoder for the embarked-column\n",
    "# Make sure you don't apply one of them to the whole\n",
    "# dataframe, but on individual columns only!\n",
    "from sklearn import preprocessing\n",
    "oe = preprocessing.OrdinalEncoder().fit(X[[\"sex\"]])\n",
    "X[[\"sex\"]] = oe.transform(X[[\"sex\"]])\n",
    "\n",
    "ohe = preprocessing.OneHotEncoder().fit(X[[\"embarked\"]])\n",
    "embarks = ohe.transform(X[[\"embarked\"]]).toarray()\n",
    "embarks = pd.DataFrame(embarks, columns=[\"London\", \"Queenstown\", \"Southampton\"])\n",
    "X = pd.concat([X, embarks], axis=1)\n",
    "X.drop([\"embarked\"],  axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20822892",
   "metadata": {},
   "source": [
    "Zum Abschluss dieses Teils, und zur Repetition, werden die `age`- und `fare`-Werte normalisiert - Sie k√∂nnen hierzu entweder den `MinMaxScaler` verwenden, den Sie aus der `LA_1650` kennen, oder sich am [`StandardScaler`](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling) versuchen. Letzter grenzt die Werte nicht auf zwischen 0 und 1 ein, sondern berechnet die Werte so, dass deren Mittel bei 0 liegt und ihre Varianz bei 1.\n",
    "\n",
    "Zun√§chst muss unser `standard_scaler` allerdings berechnen, was das Mittel und die Varianz sind. Dann k√∂nnen wir ihn verwenden, um sowohl unsere `X`-Daten wie auch am Ende neue Daten, f√ºr die wir eine Vorhersage treffen m√∂chten, konsistenz zu skalieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9adefbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>party_size</th>\n",
       "      <th>London</th>\n",
       "      <th>Queenstown</th>\n",
       "      <th>Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.664649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.786286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.472073</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.205912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.183382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.947034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.204819</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.931379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.391221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass       age  sex      fare party_size  London  Queenstown  Southampton\n",
       "0      3 -0.664649  0.0 -0.489393          1     0.0         1.0          0.0\n",
       "1      3  0.786286  1.0 -0.472073          1     0.0         0.0          1.0\n",
       "2      3  0.205912  0.0 -0.183382          3     0.0         0.0          1.0\n",
       "3      2  1.947034  0.0 -0.204819          5     0.0         0.0          1.0\n",
       "4      2  0.931379  1.0 -0.391221          1     0.0         0.0          1.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler = preprocessing.StandardScaler().fit(X[[\"age\", \"fare\"]])\n",
    "\n",
    "def scale(dataframe, columns, scaler):\n",
    "    scaled = scaler.transform(dataframe[columns])\n",
    "    dataframe[columns] = pd.DataFrame(scaled, columns=columns)\n",
    "    return dataframe\n",
    "\n",
    "X = scale(X, [\"age\", \"fare\"], standard_scaler)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a542116",
   "metadata": {},
   "source": [
    "## Teil 4: *test-train-split*\n",
    "\n",
    "Dieser Teil wird Ihnen dank `pandas` sehr einfach gemacht. Teilen Sie Ihre `X` und `y` in `train_X`, `train_y`, `test_X` und `test_y` ein, und zwar so, dass 20% der Daten zum Testen verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6123acfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680, 170)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Split the titanic data into suitable test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008d177",
   "metadata": {},
   "source": [
    "## Teil 5: Algorithmuswahl\n",
    "\n",
    "*Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.*, wobei mit *estimator* hier der Algorithmus gemeint ist. Es gibt nicht eine zwingende Zuordnung √† la *der Algorithmus XYZ ist immer der Beste*, sondern die Wahl h√§ngt von Ihrem Problem, Ihren Daten, Ihren verf√ºgbaren Ressourcen und Ihrer Erfahrung im *parameter tuning* ab. Wir greifen hier bereits etwas vor und zeigen Ihnen eine beliebte Technik, um einen passenden Algorithmus zu finden; und gehen im Anschlu√ü auf diesen Auftrag auf einige verwandte Themen vertieft ein.\n",
    "\n",
    "Diese Technik, die auch bei Ge√ºbteren oft zum Einsatz kommt, ist es, eine Batterie von Algorithmen als Kandidaten auszuw√§hlen, alle diese auf den *train*-Daten laufenzulassen und daraufhin zu √ºberpr√ºfen, welcher dieser Kandidaten auf den Test-Daten die genauesten Vorhersagen trifft.\n",
    "\n",
    "Im nachfolgenden Block wurden schon einige passende Algorithmen zusammengestellt, welche Sie nun nach der Reihe laufen lassen k√∂nnen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0a7e49ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.79\n",
      "Stochastic Gradient Descent 0.76\n",
      "Linear SVM 0.75\n",
      "Gaussian Process 0.81\n",
      "Decision Tree 0.82\n",
      "Random Forest 0.81\n",
      "Neural Net 0.81\n",
      "Naive Bayes 0.78\n",
      "LDA 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "algorithms = {\n",
    "    \"Nearest Neighbors\" : KNeighborsClassifier(3),\n",
    "    \"Stochastic Gradient Descent\" : SGDClassifier(),\n",
    "    \"Linear SVM\" : SVC(kernel=\"linear\", C=0.025),\n",
    "    \"Gaussian Process\" : GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    \"Decision Tree\" : DecisionTreeClassifier(max_depth=5),\n",
    "    \"Random Forest\" : RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"Neural Net\" : MLPClassifier(alpha=1, max_iter=1000),\n",
    "    \"Naive Bayes\" : GaussianNB(),\n",
    "    \"LDA\" : LinearDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "\n",
    "for name, algorithm in algorithms.items():\n",
    "    # üëæ TODO: Run each algorithm on X_train and y_train\n",
    "    # using the .fit function; then evaluate it using\n",
    "    # algorithm.score(X_test, y_test) and print the\n",
    "    # name and score for each algorithm - which one \n",
    "    # performs the best?\n",
    "    \n",
    "    # You might need to use y_train.values.ravel()\n",
    "    # rather than y_train in the fit()-function\n",
    "    algorithm.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    score = algorithm.score(X_test, y_test)\n",
    "    print(name, round(score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ac39f",
   "metadata": {},
   "source": [
    "Wenn Sie den obigen Code-Block mehrfach ausf√ºhren, stellen Sie m√∂glicherweise kleine Variationen fest: Das liegt daran, dass nicht alle Algorithmen deterministisch ablaufen, sondern zu einem kleinen Grad zuf√§llig. Trotzdem sollte sich unser bereits bekannter Freund *Entscheidungsbaum* (und sein Artverwandter, der *Random Forest*) ziemlich weit oben in der Rangreihenfolge befinden. \n",
    "\n",
    "Was diese anderen Modelle bedeuten; was die Parameter wie Beispielsweise `MLPClassifier(alpha=1, max_iter=1000)` bedeuten und wie der `score` berechnet wird, darauf wird in sp√§teren Auftr√§gen genauer eingegangen. Doch f√ºr's erste haben Sie den schwierigsten Teil geschafft! üëè \n",
    "\n",
    "## Teil 6: Modell speichern\n",
    "\n",
    "Sehen Sie in der `LA_1650` und der [Dokumentation](https://scikit-learn.org/stable/modules/model_persistence.html) nach, wie Sie das beste Modell speichern und wieder laden, damit Sie es in Zukunft bereit haben, sollte wieder ein Atlantikdampfer einen Eisberg √ºbersehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a9ac28eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Save the best model with titanic_algorithm.joblib as\n",
    "# its filename, then load it again into the best_model variable. \n",
    "# Note: The trained model is saved in the appropriate entry in \n",
    "# the algorithms-dictionary\n",
    "\n",
    "import joblib\n",
    "joblib.dump(algorithms[\"Random Forest\"], 'titanic_random_forest.joblib')\n",
    "best_model = joblib.load('titanic_random_forest.joblib')\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d8820",
   "metadata": {},
   "source": [
    "## Teil 7: Vorhersagen treffen\n",
    "\n",
    "Sie kennen vermutlich den 1997 Film √ºber die Titanic - wenn nicht, planen Sie sich mittelfristig 2.5 Stunden Zeit ein f√ºr ein St√ºck Hollywood'scher Zeitgeschichte. Auf jeden Fall: In diesem Film besteigen Leonardo di Caprio und Kate Winslet die Titanic, verlieben sich und, nun ja, bleiben vom Untergang der Titanic nicht verschont.\n",
    "\n",
    "Fragen Sie Ihr Modell, wie warscheinlich es f√ºr die beiden jeweils ist, dass sie den Untergang √ºberleben. Leonardo spielt einen 20-j√§hrigen, der bei einem Pokerspiel eine Drittklass-Fahrkarte gewinnt (nehmen wir an mit einem Wert von 7.5 Pfund, was heute immerhin 850 CHF entspr√§che); Kate eine 17-j√§hrige, welche erste Klasse (f√ºr angenommene 99.95 Pfund) f√§hrt; im Schlepptau Ihre Mutter und Ihren Mann, den Sie mit Leonardo betr√ºgt. Beide steigen in Southampton ein.\n",
    "\n",
    "‚ö†Ô∏è Denken Sie daran, dass Sie die gleichen Transformationen auf Ihre Daten anwenden m√ºssen, die Sie f√ºr die *train*-Daten angewendet haben!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b20b84f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fare</th>\n",
       "      <th>party_size</th>\n",
       "      <th>London</th>\n",
       "      <th>Queenstown</th>\n",
       "      <th>Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.519556</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.493742</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.737196</td>\n",
       "      <td>1</td>\n",
       "      <td>1.229547</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass       age  sex      fare  party_size  London  Queenstown  \\\n",
       "0       3 -0.519556    0 -0.493742           1       0           0   \n",
       "0       1 -0.737196    1  1.229547           3       0           0   \n",
       "\n",
       "   Southampton  \n",
       "0            1  \n",
       "0            1  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üëæ TODO: Create a new dataframe with the appropriate values\n",
    "# Remember that our X-data has the following order:\n",
    "# pclass \tage \tsex \tfare \tparty_size \tLondon \tQueenstown \tSouthhampton\n",
    "# Then, use the standard_scaler and the scale()-function\n",
    "# defined above to scale your dataframe\n",
    "\n",
    "leo = pd.DataFrame([[3, 20, 0, 7.5, 1, 0, 0, 1]], columns=X_train.columns)\n",
    "leo = scale(leo, [\"age\", \"fare\"], standard_scaler)\n",
    "leo.head()\n",
    "\n",
    "kate = pd.DataFrame([[1, 17, 1, 99.95, 3, 0, 0, 1]], columns=X_train.columns)\n",
    "kate = scale(kate, [\"age\", \"fare\"], standard_scaler)\n",
    "kate.head()\n",
    "\n",
    "lovebirds_at_sea = pd.concat([leo, kate])\n",
    "lovebirds_at_sea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f44f3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leo stribt üòµ\n",
      "Kate lebt ü•≥\n"
     ]
    }
   ],
   "source": [
    "# üëæ TODO: finally, use the predict()-function\n",
    "# to see what would've happened to you. The return\n",
    "# value of the predict()-function is an array, of\n",
    "# which array[0] contains the classification:\n",
    "# 1 for survival, 0 for, well, not surviving\n",
    "\n",
    "predictions = best_model.predict(pd.concat([leo, kate]))\n",
    "for person, prediction in zip([\"Leo\", \"Kate\"], predictions):\n",
    "    print(f\"{person} {'stribt üòµ' if prediction == 0  else 'lebt ü•≥'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ef185",
   "metadata": {},
   "source": [
    "## Bonus-Etappe\n",
    "\n",
    "Sie bekommen beim Herumspielen sicher ein Gef√ºhl daf√ºr, dass gewisse Merkmale eine gr√∂√üe Auswirkung auf das Resultat haben als andere. Eine M√∂glichkeit, wissenschaftlich an die Frage heranzugehen, wie gro√ü diese Auswirkung ist, ist die Folgende: Das Modell wird neu berechnet und gleich auf den Test-Daten gepr√ºft, aber bei jedem Durchgang wird ein Merkmal (also einmal das Alter, einmal das Geschlecht etc.) weggelassen. Nun l√§sst sich herausfinden, wie die Leistung des Modells sinkt: Wird ein wichtiges Merkmal weggelassen, dann sinkt die Leistung betr√§chtlich; sinkt sie nur wenig, war das weggelassene Merkmal nicht wichtig. Diese Technik nennt sich *permutation importance*. Zum Gl√ºck m√ºssen Sie das nicht von Hand tun, sondern k√∂nnen auf praktische Funktionen zur√ºckgreifen!\n",
    "\n",
    "‚ö†Ô∏è Wenn gewisse Merkmale *abh√§ngig* voneinander sind, das heisst, wenn sich das eine Merkmal gut durch das andere vorhersagen l√§sst, dann funktioniert die *permutation importance* weniger gut. In unserem Beispiel ist das Resultat also mit vorsicht zu genie√üen, weil vermutlich `pclass` und `fare` von einander abh√§ngen - eine Fahrkarte erster Klasse ist teurer als eine dritter Klasse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "41335922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean decrease in impurity')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    best_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=X_train.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar()\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45060bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
